# âœ‹ Gesture-to-Voice Translator | AI + Computer Vision

A real-time **hand gesture recognition** and **voice output system** built using  
**MediaPipe + OpenCV + Python + Text-to-Speech (pyttsx3)**.  

This project detects the number of fingers shown in front of the camera and speaks  
the corresponding voice command (e.g., â€œOneâ€, â€œTwoâ€, â€œHelloâ€, etc.).  
It can be extended to support custom gestures for accessibility, smart home control,  
robotics, and silent communication.

---

## ğŸš€ Features

- âœ”ï¸ Real-time hand detection using MediaPipe  
- âœ”ï¸ Detects finger counts (0â€“5) with high accuracy  
- âœ”ï¸ Converts gestures into **voice output**  
- âœ”ï¸ Fast and optimized â€” lower resolution processing for better FPS  
- âœ”ï¸ Works offline (no internet required)  
- âœ”ï¸ Easily extendable with custom gestures  

---

## ğŸ¥ Demo Output (Sample)

| Gesture | System Says |
|--------|-------------|
| âœŠ Fist | â€œFistâ€ |
| â˜ï¸ One Finger | â€œOneâ€ |
| âœŒï¸ Two Fingers | â€œTwoâ€ |
| ğŸ¤Ÿ Three Fingers | â€œThreeâ€ |
| ğŸ–ï¸ Five Fingers | â€œHelloâ€ |

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **OpenCV** â†’ Camera capture & image processing  
- **MediaPipe Hands** â†’ Gesture & landmark detection  
- **pyttsx3** â†’ Offline Text-to-Speech voice output  
- **Threading** â†’ Non-blocking voice playback  

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone this repository:
```bash
git clone https://github.com/YourUsername/Gesture-Voice-Translator.git
cd Gesture-Voice-Translator
